{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_small.xlsx\"\n",
    "indices = [17, 19]\n",
    "filePath = \"C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\scrapes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting 394 reviews\n",
      "scrolling...\n",
      "finished scrolling, found 393 reviews\n",
      "preparing to scrape location with key 1000804781\n",
      "scraped location with key 1000804781 with 393 reviews\n",
      "sum of all rows: 393\n",
      "total rows: 393\n"
     ]
    }
   ],
   "source": [
    "simpleScraper(sourceFile, searchTerms, key, indices=indices, wait=[1,2], combine=False, filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Name':['Tom', 'nick', 'krish', 'jack'], 'Age':[20, 21, 19, 18]} \n",
    "df = pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.google.com/search?q=Pizza Hut+10021004 Chestnut St+EMMAUS+PA\"\n",
    "driver = webdriver.Chrome('./chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)\n",
    "addr = driver.find_elements_by_xpath(\"//span[@class='LrzXr']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0,2]\n",
    "age_final = [23, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\scrapes\\\\'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath + \"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "workfile = pd.read_excel(\"workfile.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_trimmed = workfile[workfile[\"Company ID\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = np.array_split(work_trimmed, len(work_trimmed)/500)\n",
    "for df in dfs:\n",
    "    first_index = str(df.first_valid_index())\n",
    "    last_index = str(df.last_valid_index())\n",
    "    filename = \"workfile_\" + first_index + \"_\" + last_index + \".xlsx\"\n",
    "    df.to_excel(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1291'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dfs[0].last_valid_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9/29/20 3:21 scrape\n",
    "# 256-306 (50 locations)\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_530_1059.xlsx\"\n",
    "indices = list(range(256,307))\n",
    "filePath = \"C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms, key=key, indices=indices, wait=[1,2], combine=False, statusCol=\"Status\", filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(256,530))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthony = pd.read_csv(\"./py_files/anthony.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Empty\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Name  Age Empty\n0    Tom   20      \n1   nick   21      \n2  krish   19      \n3   jack   18      ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Age</th>\n      <th>Empty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tom</td>\n      <td>20</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>nick</td>\n      <td>21</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>krish</td>\n      <td>19</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>jack</td>\n      <td>18</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthony[\"Status\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "anthony.to_csv(\"./py_files/anthony.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anthony's scrape\n",
    "searchTerms = [\"Name\", \"Street_Address\", \"City\", \"State\"]\n",
    "key = \"Keyword\"\n",
    "sourceFile = \"anthony.csv\"\n",
    "indices = list(range(0,64))\n",
    "filePath = \"/home/spencer/Documents/Projects/scrape/py_files/anthony_scrapes\"\n",
    "# failed after 40 scrapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second round of anthony scrapes\n",
    "searchTerms = [\"Name\", \"Street_Address\", \"City\", \"State\"]\n",
    "key = \"Keyword\"\n",
    "sourceFile = \"anthony.csv\"\n",
    "indices = list(range(40,64))\n",
    "filePath = \"/home/spencer/Documents/Projects/scrape/py_files/anthony_scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one more anthony scrape, last was successful but I missed a location\n",
    "searchTerms = [\"Name\", \"Street_Address\", \"City\", \"State\"]\n",
    "key = \"Keyword\"\n",
    "sourceFile = \"anthony.csv\"\n",
    "indices = [64]\n",
    "filePath = \"C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\anthony_scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "donatos = pd.read_excel(\"donatos.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "donatos[\"Field2\"] = [\" \".join(r.split(\" \")[:-3]) for r in donatos[\"Field2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "donatos[\"Name\"] = [\" \".join(r.split(\" \")[:2]) for r in donatos[\"Field2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;Donatos&#39;, &#39;Pizza&#39;, &#39;1013&#39;, &#39;High&#39;, &#39;St&#39;, &#39;HAMILTON&#39;, &#39;OH&#39;]"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "donatos[\"Field2\"][27].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "donatos[\"State\"] = [r.split(\" \")[-1] for r in donatos[\"Field2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "townpieces = [r.split(\" \")[-3:-1] for r in donatos[\"Field2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "donatos[\"Town\"] = [\" \".join(t) if t[0].isupper() else t[1] for t in townpieces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "addrpieces = [r.split(\" \")[2:-2] for r in donatos[\"Field2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "donatos[\"Address\"] = [\" \".join(a[0:-1]) if a[-1].isupper() else \" \".join(a[0:]) for a in addrpieces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "donatos[\"Status\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                Field2      Unnamed: 1  \\\n0          Donatos Pizza 825 W 10th St INDIANAPOLIS IN  (317) 231-9700   \n1            Donatos Pizza 92 S Highway 27 SOMERSET KY  (606) 677-1700   \n2         Donatos Pizza 2357 E 62nd St INDIANAPOLIS IN  (317) 722-8100   \n3           Donatos Pizza 3390 Maple Ave ZANESVILLE OH  (740) 452-7900   \n4         Donatos Pizza 6407 Glenway Ave CINCINNATI OH  (513) 598-4200   \n..                                                 ...             ...   \n150  Donatos Pizza 12515 Jefferson Ave NEWPORT NEWS VA  (757) 525-4944   \n151       Donatos Pizza 3464 Wales Ave NW MASSILLON OH  (330) 833-3700   \n152      Donatos Pizza 2601 W Parrish Ave OWENSBORO KY  (270) 855-0801   \n153  Donatos Pizza 220 Azalea Square Blvd SUMMERVIL...  (843) 501-2838   \n154     Donatos Pizza 3284 Franklin Rd MURFREESBORO TN  (615) 900-5500   \n\n                                              Page URL           Name  \\\n0    https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n1    https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n2    https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n3    https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n4    https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n..                                                 ...            ...   \n150  https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n151  https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n152  https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n153  https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n154  https://www.google.com/maps/place/Donatos+Pizz...  Donatos Pizza   \n\n                    Address State          Town Status  \n0             825 W 10th St    IN  INDIANAPOLIS         \n1           92 S Highway 27    KY      SOMERSET         \n2            2357 E 62nd St    IN  INDIANAPOLIS         \n3            3390 Maple Ave    OH    ZANESVILLE         \n4          6407 Glenway Ave    OH    CINCINNATI         \n..                      ...   ...           ...    ...  \n150     12515 Jefferson Ave    VA  NEWPORT NEWS         \n151          3464 Wales Ave    OH  NW MASSILLON         \n152      2601 W Parrish Ave    KY     OWENSBORO         \n153  220 Azalea Square Blvd    SC   SUMMERVILLE         \n154        3284 Franklin Rd    TN  MURFREESBORO         \n\n[155 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Field2</th>\n      <th>Unnamed: 1</th>\n      <th>Page URL</th>\n      <th>Name</th>\n      <th>Address</th>\n      <th>State</th>\n      <th>Town</th>\n      <th>Status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>Donatos Pizza 825 W 10th St INDIANAPOLIS IN</td>\n      <td>(317) 231-9700</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>825 W 10th St</td>\n      <td>IN</td>\n      <td>INDIANAPOLIS</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>Donatos Pizza 92 S Highway 27 SOMERSET KY</td>\n      <td>(606) 677-1700</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>92 S Highway 27</td>\n      <td>KY</td>\n      <td>SOMERSET</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>Donatos Pizza 2357 E 62nd St INDIANAPOLIS IN</td>\n      <td>(317) 722-8100</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>2357 E 62nd St</td>\n      <td>IN</td>\n      <td>INDIANAPOLIS</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>Donatos Pizza 3390 Maple Ave ZANESVILLE OH</td>\n      <td>(740) 452-7900</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>3390 Maple Ave</td>\n      <td>OH</td>\n      <td>ZANESVILLE</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>Donatos Pizza 6407 Glenway Ave CINCINNATI OH</td>\n      <td>(513) 598-4200</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>6407 Glenway Ave</td>\n      <td>OH</td>\n      <td>CINCINNATI</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>Donatos Pizza 12515 Jefferson Ave NEWPORT NEWS VA</td>\n      <td>(757) 525-4944</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>12515 Jefferson Ave</td>\n      <td>VA</td>\n      <td>NEWPORT NEWS</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>151</td>\n      <td>Donatos Pizza 3464 Wales Ave NW MASSILLON OH</td>\n      <td>(330) 833-3700</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>3464 Wales Ave</td>\n      <td>OH</td>\n      <td>NW MASSILLON</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>152</td>\n      <td>Donatos Pizza 2601 W Parrish Ave OWENSBORO KY</td>\n      <td>(270) 855-0801</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>2601 W Parrish Ave</td>\n      <td>KY</td>\n      <td>OWENSBORO</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>153</td>\n      <td>Donatos Pizza 220 Azalea Square Blvd SUMMERVIL...</td>\n      <td>(843) 501-2838</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>220 Azalea Square Blvd</td>\n      <td>SC</td>\n      <td>SUMMERVILLE</td>\n      <td></td>\n    </tr>\n    <tr>\n      <td>154</td>\n      <td>Donatos Pizza 3284 Franklin Rd MURFREESBORO TN</td>\n      <td>(615) 900-5500</td>\n      <td>https://www.google.com/maps/place/Donatos+Pizz...</td>\n      <td>Donatos Pizza</td>\n      <td>3284 Franklin Rd</td>\n      <td>TN</td>\n      <td>MURFREESBORO</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>155 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "donatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "donatos.to_csv(\"donatos.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donatos scrape\n",
    "searchTerms = [\"Name\", \"Address\", \"Town\", \"State\"]\n",
    "key = \"Field2\"\n",
    "sourceFile = \"donatos.csv\"\n",
    "indices = list(range(0,155))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pizza hut scrape 9/30\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_530_1059.xlsx\"\n",
    "indices = list(range(257,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)\n",
    "# successfully scraped 248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pizza hut scrape 10/1\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_1060_1589.xlsx\"\n",
    "indices = list(range(0,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pizza hut scrape 10/1 #2\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_1590_2119.xlsx\"\n",
    "indices = list(range(0,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)\n",
    "# i know there is an issue with some locations not scrolling all the way. ill need to find a way to test outputs spreadsheets for this, but most seemed to work out well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pizza hut scrape 10/2 #1\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_2120_2649.xlsx\"\n",
    "indices = list(range(0,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "24"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "anthony = pd.read_csv(\".\\\\py_files\\\\anthony_.csv\")\n",
    "anthony[\"Status\"].unique()\n",
    "# so, it appears all anthony's locations scraped properly\n",
    "# i'll check if there are locations with data that weren't scraped\n",
    "len(anthony[(anthony[\"Status\"].isnull()) & (anthony[\"Keyword\"].notnull())])\n",
    "# many were not marked as scraped, but there are 65 locations and i have 65 scrapes, so it's fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "donatos = pd.read_csv(\".\\\\py_files\\\\donatos_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "len(donatos[donatos[\"Status\"]==\"Scraped\"]) # 136, this corresponds to the 136 i have scraped\n",
    "len(donatos[donatos[\"Status\"]==\"Failed\"]) # 19 failed locations i will separate\n",
    "len(donatos[(donatos[\"Status\"].isnull()) & (donatos[\"Field2\"].notnull())]) # 0 locations with no attempted scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaprate donatos failures into their own csv\n",
    "donatos_f = donatos[donatos[\"Status\"]==\"Failed\"]\n",
    "donatos_f.to_csv(\"donatos_f.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "19"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# donatos scrape to see what the issues were\n",
    "searchTerms = [\"Name\", \"Address\", \"Town\", \"State\"]\n",
    "key = \"Field2\"\n",
    "sourceFile = \".\\\\rescrape\\\\donatos_f.csv\"\n",
    "indices = list(range(0,19))\n",
    "filePath = \"C:\\\\Users\\\\Spencer\\\\Desktop\\\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)\n",
    "# a new error came up, something about casting arrays to different sizes, trying to debug\n",
    "# got it working. made a slight adjustment to how statuses are updated\n",
    "# second run without address checks as they were all unneeded:\n",
    "searchTerms = [\"Name\", \"Address\", \"Town\", \"State\"]\n",
    "key = \"Field2\"\n",
    "sourceFile = \"donatos_f.csv\"\n",
    "indices = list(range(0,19))\n",
    "filePath = \"C:\\\\Users\\\\Spencer\\\\Desktop\\\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores =  pd.read_excel(\"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\datasets\\\\data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([\"Anthony's Coal Fired Pizza\", 'Bananas Ultimate Juice Bar',\n",
       "       'Blackjack Pizza', 'Blaze Pizza',\n",
       "       \"Boston's The Gourmet Pizza Restaurant & Sports Bar\",\n",
       "       \"BOSTON'S THE GOURMET PIZZA RESTAURANT & SPORTS BAR\",\n",
       "       'Brick Oven Pizza Company', 'Brixx Wood Fired Pizza',\n",
       "       'California Pizza Kitchen', 'Chanellos Pizza', \"Chanello's Pizza\",\n",
       "       'CheeZies Pizza', \"Chuck E. Cheese's\", \"CiCi's Pizza\",\n",
       "       \"CiCi's To Go\", 'Cobalt', 'Cottage Inn Pizza', 'CPK ASAP',\n",
       "       \"D'Angelo Grilled Sandwiches\", 'Deweys Pizza', \"Domino's\",\n",
       "       'Donatos Pizza', 'Extreme Pizza', \"Figaro's Pizza\",\n",
       "       \"Fox's Pizza Den\", 'GattiLand', \"Gatti's Pizza\",\n",
       "       \"Gatti's Pizza Buffet\", 'GattiTown',\n",
       "       \"Giordano's Restaurant & Pizza\", \"Godfather's Pizza\",\n",
       "       \"Green Leaf's Grill & Bananas Ultimate Juice Bar\",\n",
       "       \"Guille's Mexican Grill\", \"Hungry Howie's Pizza\",\n",
       "       \"Hungry Howie's Pizza & Subs\", \"Jet's Pizza\",\n",
       "       \"Johnnie's New York Pizzeria\",\n",
       "       'Johnny Bruscos New York Style Pizza',\n",
       "       'Johnnys New York Style Pizza', \"LaRosa's Pizzeria\", 'Ledo Pizza',\n",
       "       \"Little Caesar's\", 'Little Caesars Pizza', 'Lou Malnatis Pizzeria',\n",
       "       'Loumalnatis', \"Marco's Pizza\", \"Marco's pizza\", 'Mellow Mushroom',\n",
       "       'MOD Pizza', 'Monicals Pizza', \"Mountain Mike's Pizza\",\n",
       "       \"Nick 'N' Willy's\", 'Old Chicago Pizza & Taproom', 'Paisanos',\n",
       "       \"Paisano's Pizza\", \"Papa Gino's Pizzeria\", \"Papa John's Pizza\",\n",
       "       \"Papa Murphy's Take 'N' Bake Pizza\", 'Peter Piper Pizza',\n",
       "       'Pie Five Pizza', 'PIEOLOGY PIZZERIA', 'Pizza Bolis',\n",
       "       \"Pizza Boli's\", 'Pizza Factory', 'PIZZA FACTORY', 'Pizza Guys',\n",
       "       'Pizza Hut', 'PIZZA HUT', 'Pizza Inn', 'Pizza Inn Express',\n",
       "       'Pizza Italia', 'Pizza Plus', 'Pizza Pro', 'Pizza Schmizza',\n",
       "       'PizzaRev', 'Pizzeria Locale', 'Rosatis Pizza', 'ROSATIS PIZZA',\n",
       "       'Round Table Pizza', 'ROUND TABLE PIZZA', 'Sbarro',\n",
       "       'Schmizza Pub & Grub', 'Schmizza Public House',\n",
       "       \"Shakey's Pizza Parlor\", \"Simple Simon's Pizza\",\n",
       "       'Snappy Tomato Pizza', 'South Philly Steaks & Fries',\n",
       "       'Steelworks Buffett & Grill', 'Straw Hat Grill', 'Straw Hat Pizza',\n",
       "       'Sukotto', 'The Market', 'The Market by Villa',\n",
       "       'The Office Beer Bar & Grill', 'The Original Italian Pie',\n",
       "       'The Pizza Ranch', 'Toppers Pizza', 'Villa Fresh Italian Kitchen',\n",
       "       'Villa Pizza', 'Vocelli Pizza', 'VOCELLI PIZZA', 'zpizza'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "all_stores[\"Company Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpk = all_stores[all_stores[\"Company Name\"] == \"California Pizza Kitchen\"]\n",
    "cpk.to_csv(\"cpk.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chuckecheese = all_stores[all_stores[\"Company Name\"] == \"Chuck E. Cheese's\"]\n",
    "chuckecheese.to_csv(\"chuckecheese.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pizzaranch = all_stores[all_stores[\"Company Name\"] == \"The Pizza Ranch\"]\n",
    "pizzaranch.to_csv(\"pizzaranch.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "192\n531\n207\n"
    }
   ],
   "source": [
    "print(len(cpk))\n",
    "print(len(chuckecheese))\n",
    "print(len(pizzaranch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pizza hut scrape 10/5 #1\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_2650_3179.xlsx\"\n",
    "indices = list(range(0,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)\n",
    "# having error after index 11, doing ones after\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_2650_3179.xlsx\"\n",
    "indices = list(range(12,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)\n",
    "# failed again after index 34, continuing\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_2650_3179.xlsx\"\n",
    "indices = list(range(35,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)\n",
    "# this was mostly successful but failed to save the marked input file due to an error. FIX THIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next pizza hut scrape\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_4240_4769.xlsx\"\n",
    "indices = list(range(0,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pizza hut scrape 10/6\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_4770_5299.xlsx\"\n",
    "indices = list(range(0,530))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pizza hut scrape 10/6 #2 (final standard pizza hut scrape)\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_5300_5828.xlsx\"\n",
    "indices = list(range(0,529))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath)\n",
    "# this went well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuck e cheese scrape\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"chuckecheese.csv\"\n",
    "indices = list(range(0,531))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)\n",
    "# going to try to do this with no address check\n",
    "# got the first 312 stores. took a long time and ended when selenium crashed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuck e cheese scrape part 2, only doing some since i have to go home later today. 10/9\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"chuckecheese.csv\"\n",
    "indices = list(range(310, 385))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuck e cheese scrape part 3, only got like 50 done yesterday. this is so slow. 10/10\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"chuckecheese.csv\"\n",
    "indices = list(range(362, 432))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chuck e cheese scrape part 4, hopefully finishing. 10/10\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"chuckecheese.csv\"\n",
    "indices = list(range(432, 531))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pizza ranch 10/12\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"cpk.csv\"\n",
    "indices = list(range(0, 192))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpk\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"cpk.csv\"\n",
    "indices = list(range(0, 192))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting datasets for all locations\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores =  pd.read_excel(\"C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\datasets\\\\data.xlsx\")\n",
    "names = all_stores[\"Company Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    df = all_stores[all_stores[\"Company Name\"] == name]\n",
    "    df[\"Status\"] = \"\"\n",
    "    fName = name.replace(\" \",\"_\").replace(\"'\",\"\").replace(\".\",\"\").lower() + \".csv\"\n",
    "    df.to_csv(fName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"locations.txt\", 'w') as file:\n",
    "    for name in names:\n",
    "        file.write(name+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# papa murphys\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"papa_murphys_take_n_bake_pizza.csv\"\n",
    "indices = list(range(0, 1340))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# papa murphys (round 2)\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"papa_murphys_take_n_bake_pizza.csv\"\n",
    "indices = list(range(266, 1340))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blaze\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"blaze_pizza.csv\"\n",
    "indices = list(range(0, 320))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blaze had a timeout error, i need to put a try except block that reloads the page if it can't find that element\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"blaze_pizza.csv\"\n",
    "indices = list(range(129, 320))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mellow mushroom\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"mellow_mushroom.csv\"\n",
    "indices = list(range(0, 189))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mellow mushroom 2\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"mellow_mushroom.csv\"\n",
    "indices = list(range(125, 189))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbarro\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"sbarro.csv\"\n",
    "indices = list(range(0, 305))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbarro 2\n",
    "# index 121 is a mall, not a sbarros, so i skipped it\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"sbarro.csv\"\n",
    "indices = list(range(122, 305))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sbarro 3\n",
    "# found another that isnt a sbarro, skipping index 144\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"sbarro.csv\"\n",
    "indices = list(range(145, 305))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round table\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"round_table_pizza.csv\"\n",
    "indices = list(range(0, 5))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# villa pizza\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"villa_pizza.csv\"\n",
    "indices = list(range(0, 17))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# villa pizza # 2\n",
    "# skipping index 8, a mall\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"villa_pizza.csv\"\n",
    "indices = list(range(9, 17))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# villa pizza #3 other set\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"villa_fresh_italian_kitchen.csv\"\n",
    "indices = list(range(0, 158))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get datasets again, this time processing names before exporting them\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores =  pd.read_excel(\"C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\datasets\\\\data.xlsx\")\n",
    "names = all_stores[\"Company Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_names(instr):\n",
    "    retstr = instr.replace(\" \",\"_\").replace(\"'\",\"\").replace(\".\",\"\").lower()\n",
    "    return retstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stores[\"Company Name Processed\"] = all_stores[\"Company Name\"].apply(process_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "93\n102\n"
     ]
    }
   ],
   "source": [
    "fewer_names = all_stores[\"Company Name Processed\"].unique()\n",
    "print(len(fewer_names))\n",
    "print(len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in fewer_names:\n",
    "    df = all_stores[all_stores[\"Company Name Processed\"] == name]\n",
    "    df[\"Status\"] = \"\"\n",
    "    fName = name.replace(\" \",\"_\").replace(\"'\",\"\").replace(\".\",\"\").lower() + \".csv\"\n",
    "    df.to_csv(fName, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# made some adjustments to scrolling, testing results on round table redo\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"round_table_pizza.csv\"\n",
    "indices = list(range(0, 415))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round table 2, had a timeout. i need to add a check that just reloads the page when those happen\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"round_table_pizza.csv\"\n",
    "indices = list(range(224, 415))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pieology\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"pieology_pizzeria.csv\"\n",
    "indices = list(range(0, 125))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,statusCol=\"Status\",filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting a better list of all locations\n",
    "import pandas as pd\n",
    "all_stores =  pd.read_excel(\"C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\datasets\\\\data.xlsx\")\n",
    "names = all_stores[\"Company Name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_names_no_underscore(instr):\n",
    "    retstr = instr.replace(\"'\",\"\").replace(\".\",\"\").lower()\n",
    "    return retstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['anthonys coal fired pizza', 'bananas ultimate juice bar',\n",
       "       'blackjack pizza', 'blaze pizza',\n",
       "       'bostons the gourmet pizza restaurant & sports bar',\n",
       "       'brick oven pizza company', 'brixx wood fired pizza',\n",
       "       'california pizza kitchen', 'chanellos pizza', 'cheezies pizza',\n",
       "       'chuck e cheeses', 'cicis pizza', 'cicis to go', 'cobalt',\n",
       "       'cottage inn pizza', 'cpk asap', 'dangelo grilled sandwiches',\n",
       "       'deweys pizza', 'dominos', 'donatos pizza', 'extreme pizza',\n",
       "       'figaros pizza', 'foxs pizza den', 'gattiland', 'gattis pizza',\n",
       "       'gattis pizza buffet', 'gattitown', 'giordanos restaurant & pizza',\n",
       "       'godfathers pizza',\n",
       "       'green leafs grill & bananas ultimate juice bar',\n",
       "       'guilles mexican grill', 'hungry howies pizza',\n",
       "       'hungry howies pizza & subs', 'jets pizza',\n",
       "       'johnnies new york pizzeria',\n",
       "       'johnny bruscos new york style pizza',\n",
       "       'johnnys new york style pizza', 'larosas pizzeria', 'ledo pizza',\n",
       "       'little caesars', 'little caesars pizza', 'lou malnatis pizzeria',\n",
       "       'loumalnatis', 'marcos pizza', 'mellow mushroom', 'mod pizza',\n",
       "       'monicals pizza', 'mountain mikes pizza', 'nick n willys',\n",
       "       'old chicago pizza & taproom', 'paisanos', 'paisanos pizza',\n",
       "       'papa ginos pizzeria', 'papa johns pizza',\n",
       "       'papa murphys take n bake pizza', 'peter piper pizza',\n",
       "       'pie five pizza', 'pieology pizzeria', 'pizza bolis',\n",
       "       'pizza factory', 'pizza guys', 'pizza hut', 'pizza inn',\n",
       "       'pizza inn express', 'pizza italia', 'pizza plus', 'pizza pro',\n",
       "       'pizza schmizza', 'pizzarev', 'pizzeria locale', 'rosatis pizza',\n",
       "       'round table pizza', 'sbarro', 'schmizza pub & grub',\n",
       "       'schmizza public house', 'shakeys pizza parlor',\n",
       "       'simple simons pizza', 'snappy tomato pizza',\n",
       "       'south philly steaks & fries', 'steelworks buffett & grill',\n",
       "       'straw hat grill', 'straw hat pizza', 'sukotto', 'the market',\n",
       "       'the market by villa', 'the office beer bar & grill',\n",
       "       'the original italian pie', 'the pizza ranch', 'toppers pizza',\n",
       "       'villa fresh italian kitchen', 'villa pizza', 'vocelli pizza',\n",
       "       'zpizza'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "names = all_stores[\"Company Name\"].apply(process_names_no_underscore).unique()\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"locations.txt\", 'w') as file:\n",
    "    for name in names:\n",
    "        file.write(name+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# papa johns\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"papa_johns_pizza.csv\"\n",
    "indices = list(range(0, 2994))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# papa johns 2\n",
    "# a location had an issue where it didn't load a valid single location\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"papa_johns_pizza.csv\"\n",
    "indices = list(range(141, 2994))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[0.5,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marcos\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"marcos_pizza.csv\"\n",
    "indices = list(range(0, 898))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marcos 2\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"marcos_pizza.csv\"\n",
    "indices = list(range(302, 898))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "df = pd.read_excel(\"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\datasets\\\\data.xlsx\")\n",
    "df[\"name\"] = df[\"Company Name\"].apply(process_names_no_underscore)\n",
    "lst = df[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"counts.txt\", 'w') as file:\n",
    "    for i in range(len(lst)):\n",
    "        file.write(lst.index[i] + \": \" + str(lst[i]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod pizza 10/23\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"mod_pizza.csv\"\n",
    "indices = list(range(0, 463))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to stop mod after index 42, continue below\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"mod_pizza.csv\"\n",
    "indices = list(range(43, 463))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to stop mod after index 289, continue below\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"mod_pizza.csv\"\n",
    "indices = list(range(290, 463))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# godfathers\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"godfathers_pizza.csv\"\n",
    "indices = list(range(0, 422))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# godfathers failed after index 97, continuing\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"godfathers_pizza.csv\"\n",
    "indices = list(range(98, 422))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cicis pizza\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"cicis_pizza.csv\"\n",
    "indices = list(range(0, 396))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cicis pizza 2\n",
    "# failed after index 133\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"cicis_pizza.csv\"\n",
    "indices = list(range(135, 396))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cicis pizza 3\n",
    "# index 175 keeps failing, skipping it\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Phone\"\n",
    "sourceFile = \"cicis_pizza.csv\"\n",
    "indices = list(range(176, 396))\n",
    "filePath = \"C:\\\\Users\\\\sqbrown\\\\Desktop\\\\Work\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms,key=key,indices=indices,wait=[1,1.5],combine=False,filePath=filePath, checkAddress=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 32-bit",
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "cee85ca00bce6580cd214a3985cdc6838d6799a7943f9faf419f06b5adbb3ab1"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}