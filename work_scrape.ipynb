{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "def scrollDown(driver, reviewTotal, wait):\n",
    "    x = len(driver.find_elements_by_xpath(\"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\"))\n",
    "    lastx = x - 1\n",
    "    i = 1\n",
    "    repCount = 0\n",
    "    print(\"scrolling...\")\n",
    "    # while we expect more reviews and we haven't repeated too much\n",
    "    while ((x < reviewTotal) and (repCount < 3)):\n",
    "        # pause to not look like a bot\n",
    "        pauseScroll(wait)\n",
    "        # select list of reviews\n",
    "        elements = driver.find_elements_by_xpath(\"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\")\n",
    "        # find the last visible review and go to it\n",
    "        current_last = elements[-1]\n",
    "        current_last.location_once_scrolled_into_view\n",
    "        # wait until page loads\n",
    "        WebDriverWait(driver, 30).until(ec.invisibility_of_element_located((By.XPATH, \"//div[@class='jfk-activityIndicator-icon']\")))\n",
    "        # take the previous review count and replace it with the new one\n",
    "        lastx = x\n",
    "        x = len(driver.find_elements_by_xpath(\"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\"))\n",
    "        # if more reviews are not added to the visible reviews, mark repetition\n",
    "        if (lastx == x):\n",
    "            repCount += 1\n",
    "        else:\n",
    "            repCount = 0\n",
    "            \n",
    "    print(\"finished scrolling, found\", x, \"reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReviewTotal(driver):\n",
    "    raw = driver.find_element_by_xpath(\"//span[@class='hqzQac']\").text\n",
    "    count = int(raw.split(\" \")[0])\n",
    "    print(\"expecting\", count, \"reviews\")\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import time\n",
    "def pauseScroll(wait):\n",
    "    waitTime = 0\n",
    "    # if argument is a list\n",
    "    if (isinstance(wait, list)):\n",
    "        # check if its length is valid\n",
    "        if (len(wait) > 2) or (len(wait) < 1):\n",
    "            raise ValueError\n",
    "        # if length is valid get random number between vals\n",
    "        low = wait[0]\n",
    "        high = wait[1]\n",
    "        # check for improper types, fix if possible\n",
    "        if not isinstance(low, numbers.Number):\n",
    "            if low.isnumeric():\n",
    "                low = float(low)\n",
    "            else:\n",
    "                raise ValueError\n",
    "        if not isinstance(high, numbers.Number):\n",
    "            if high.isnumeric():\n",
    "                high = float(high)\n",
    "            else:\n",
    "                raise ValueError\n",
    "        waitTime = randTime(low, high)\n",
    "    # if argument is a number\n",
    "    elif (isinstance(wait, numbers.Number)):\n",
    "        # get the number\n",
    "        waitTime = wait\n",
    "    # if argument is a string\n",
    "    elif (isinstance(wait, str)):\n",
    "        # if argument can be parsed as a number\n",
    "        if (wait.isnumeric()):\n",
    "            # get time as a number\n",
    "            waitTime = float(wait)\n",
    "        else:\n",
    "            raise ValueError\n",
    "    time.sleep(waitTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "def randTime(low, high):\n",
    "    val = random()\n",
    "    time = low + (val  * (high - low))\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "# note that this assumes scrolling has already occurred\n",
    "def scrapeFromList(driver, key, name=True, stars=True, text=True, timeSince=True):\n",
    "    elements = driver.find_elements_by_xpath(\"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\")\n",
    "    columnsBin = [name, stars, text, timeSince]\n",
    "    columnsNames = [\"name\", \"stars\", \"text\", \"timeSince\"]\n",
    "    columnsPresent = [x for i, x in enumerate(columnsNames) if columnsBin[i]] # gets included columns\n",
    "    print(\"preparing to scrape location with key\", key)\n",
    "    \n",
    "    # text body\n",
    "    textList = []\n",
    "    if (text):\n",
    "        textPath = \".//div[@style='vertical-align:top']//div[@class='Jtu6Td']//span[@jscontroller='P7L8k']\"\n",
    "        textPathFullExtension = \"//span[@class='review-full-text']\"\n",
    "        textList = [0]*len(elements)\n",
    "        i = 0\n",
    "        for e in elements:\n",
    "            try:\n",
    "                textPartial = e.find_element_by_xpath(textPath+textPathFullExtension)\n",
    "                e.find_element_by_xpath(textPath+\"//span[@role='button']\").click()\n",
    "                textList[i] = e.find_element_by_xpath(textPath).text\n",
    "            except NoSuchElementException:\n",
    "                textList[i] = e.find_element_by_xpath(textPath).text\n",
    "            i += 1\n",
    "        \n",
    "    # name\n",
    "    nameList = []\n",
    "    if (name):\n",
    "        namePath = \".//div[@class='TSUbDb']\"\n",
    "        nameList = [e.find_element_by_xpath(namePath).text for e in elements]\n",
    "    \n",
    "    # stars\n",
    "    starsList = []\n",
    "    if (stars):\n",
    "        starsPath = \".//div[@style='vertical-align:top']//div[@class='PuaHbe']//g-review-stars[@style='padding-right:7px']//span[@class='Fam1ne EBe2gf']\"\n",
    "        i = 0\n",
    "        starsList = [0]*len(elements)\n",
    "        for e in elements:\n",
    "            raw = e.find_element_by_xpath(starsPath).get_attribute(\"aria-label\")\n",
    "            starCount = raw.split(\" \")[1] # the number of stars\n",
    "            starsList[i] = float(starCount)\n",
    "            i += 1\n",
    "    \n",
    "    # timeSince\n",
    "    timeSinceList = []\n",
    "    if (timeSince):\n",
    "        timeSincePath = \".//div[@style='vertical-align:top']//div[@class='PuaHbe']\"\n",
    "        timeSinceList = [e.find_element_by_xpath(timeSincePath).text for e in elements]\n",
    "    \n",
    "    # put df together\n",
    "    columnsBin = [name, stars, text, timeSince]\n",
    "    columnsNames = [\"name\", \"stars\", \"text\", \"timeSince\"]\n",
    "    columnsPresent = [x for i, x in enumerate(columnsNames) if columnsBin[i]] # gets included columns\n",
    "    columns = [nameList, starsList, textList, timeSinceList]\n",
    "    columns = [c for c in columns if len(c) > 0]\n",
    "    data = {c:columns[i] for i,c in enumerate(columnsPresent)}\n",
    "    df = pd.DataFrame(data)\n",
    "    print(\"scraped location with key\", key, \"with\", len(df), \"reviews\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "def scrapeFromURLs(urls, checkAddress=False, combine=True, wait=[2,3]):\n",
    "    # check that urls are dicts\n",
    "    if not (isinstance(urls, dict)):\n",
    "        raise ValueError\n",
    "        \n",
    "    # start selenium stuff\n",
    "    driver = webdriver.Chrome('./chromedriver')\n",
    "    \n",
    "    dfs = [0]*len(urls)\n",
    "    \n",
    "    # for each id\n",
    "    r_count = 0\n",
    "    i = 0\n",
    "    status = [0]*len(urls)\n",
    "    for id in urls:\n",
    "        \n",
    "        # go to url\n",
    "        url = urls.get(id)\n",
    "        driver.get(url)\n",
    "        \n",
    "        # check that address is correct\n",
    "        # note this will assume the second url parameter is address number, last is state, second to last is town\n",
    "        if checkAddress:\n",
    "            parameters = url.split('=')[1].split('+') # gets the url parameters after the '=' in a list\n",
    "            addr_number = parameters[1].split(' ')[0] # gets the address number\n",
    "            town = parameters[-2].lower() # gets the town\n",
    "            state = parameters[-1].lower() # gets the state\n",
    "            addr = driver.find_element_by_xpath(\"//span[@class='LrzXr']\").text.split(',') # gets the found address as list\n",
    "            # if a check is not met, do not scrape the location, i.e. put a blank df in its final place and do not mark as done\n",
    "            found_addr_number = addr[0].split(' ')[0]\n",
    "            found_town = addr[1].lstrip(' ').lower()\n",
    "            found_state = addr[2].lstrip(' ').split(' ')[0].lower()\n",
    "            if found_addr_number != addr_number:\n",
    "                dfs[i] = pd.DataFrame({})\n",
    "                i += 1\n",
    "                print(\"failed to scrape location with key\",id,\"due to unmatched address number, continuing...\")\n",
    "                continue\n",
    "            elif found_town != town:\n",
    "                dfs[i] = pd.DataFrame({})\n",
    "                i += 1\n",
    "                print(\"failed to scrape location with key\",id,\"due to unmatched town, continuing...\")\n",
    "                continue\n",
    "            elif found_state != state:\n",
    "                dfs[i] = pd.DataFrame({})\n",
    "                i += 1\n",
    "                print(\"failed to scrape location with key\",id,\"due to unmatched state, continuing...\")\n",
    "                continue\n",
    "        \n",
    "        driver.find_element_by_class_name(\"hqzQac\").click()\n",
    "        WebDriverWait(driver, 45).until(ec.presence_of_element_located((By.XPATH, \"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\")))\n",
    "        \n",
    "        # scroll to bottom\n",
    "        scrollDown(driver, getReviewTotal(driver), wait)\n",
    "        \n",
    "        # scrape from loaded list\n",
    "        # if a scrape fails, move onto the next one\n",
    "        try:\n",
    "            df = scrapeFromList(driver, id)\n",
    "        except:\n",
    "            dfs[i] = pd.DataFrame({})\n",
    "            i += 1\n",
    "            print(\"failed to scrape location with key\",id,\", continuing...\")\n",
    "            continue\n",
    "        df[\"key\"] = str(id)\n",
    "        \n",
    "        dfs[i] = df\n",
    "        r_count += len(df)\n",
    "        status[i] = 1\n",
    "        i += 1\n",
    "        \n",
    "    # combine dfs if necessary\n",
    "    if (combine):\n",
    "        df = dfs[0]\n",
    "        # append all other dfs to the first one, then save to csv\n",
    "        for i in dfs[1:]:\n",
    "            df = df.append(i, ignore_index=True)\n",
    "        r_count_final = len(df)\n",
    "        \n",
    "        df.to_csv(\"combined_scrape_\"+str(datetime.datetime.now()).replace(' ','_').replace(':','_').replace('.','_')+\".csv\",index=False)\n",
    "    else:\n",
    "        for i in dfs:\n",
    "            i.to_csv(\"scraped_\"+str(datetime.datetime.now()).replace(' ','_').replace(':','_').replace('.','_')+\".csv\",index=False)\n",
    "    \n",
    "    # for testing if rows are lost\n",
    "    print(\"sum of all rows:\",r_count)\n",
    "    print(\"total rows:\",r_count_final)\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# make scrapeFromURLs take in a filename convention and have csvs save as it\n",
    "# add check for correct address\n",
    "# check that reviews button is there, i.e. check whether there is actually a location found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def extractURLs_csv(csv, searchTerms, key, firstIndex, lastIndex):\n",
    "    baseString = \"https://www.google.com/search?q=\"\n",
    "    \n",
    "    # read in csv (maybe add value checks later)\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # makes sure key is a list so it can be added to searchTerms\n",
    "    if (not isinstance(key, list)):\n",
    "        key = [key]\n",
    "    \n",
    "    search = df.loc[list(range(firstIndex,lastIndex+1)), searchTerms + key] # gets df with only search terms in desired rows\n",
    "    \n",
    "    search[\"url\"] = baseString + search[searchTerms[0]] # column of base plus first search term\n",
    "    # creates a column of url by adding on all other terms\n",
    "    for s in searchTerms[1:]:\n",
    "        search[\"url\"] = search[\"url\"] + \"+\" + search[s].astype(s)\n",
    "        \n",
    "    # converts key back into string\n",
    "    key = key[0]\n",
    "    \n",
    "    # returns dictionary with key of key and value of url\n",
    "    return dict(zip(list(search[key]),list(search[\"url\"])))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "def extractURLs_excel(xlsx, searchTerms, key, firstIndex, lastIndex):\n",
    "    baseString = \"https://www.google.com/search?q=\"\n",
    "    \n",
    "    # read in csv (maybe add value checks later)\n",
    "    df = pd.read_excel(xlsx)\n",
    "    \n",
    "    # makes sure key is a list so it can be added to searchTerms\n",
    "    if (not isinstance(key, list)):\n",
    "        key = [key]\n",
    "    \n",
    "    search = df.loc[list(range(firstIndex,lastIndex+1)), searchTerms + key] # gets df with only search terms in desired rows\n",
    "    \n",
    "    search[\"url\"] = baseString + search[searchTerms[0]] # column of base plus first search term\n",
    "    # creates a column of url by adding on all other terms\n",
    "    for s in searchTerms[1:]:\n",
    "        search[\"url\"] = search[\"url\"] + \"+\" + search[s].astype(str)\n",
    "        \n",
    "    # converts key back into string\n",
    "    key = key[0]\n",
    "    \n",
    "    # returns dictionary with key of key and value of url\n",
    "    return dict(zip(list(search[key]),list(search[\"url\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_small.xlsx\"\n",
    "indices = [17, 19]\n",
    "filePath = \"C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\scrapes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "def simpleScraper(sourceFile, searchTerms, key, firstIndex, lastIndex, wait=[2,3], combine=True, statusCol=None, overWrite=False):\n",
    "    \n",
    "    # get url dict\n",
    "    ext = sourceFile.split(\".\")[-1] # file extension\n",
    "    urls = {}\n",
    "    if (ext == \"xlsx\"):\n",
    "        urls = extractURLs_excel(sourceFile, searchTerms, key, firstIndex, lastIndex)\n",
    "    elif (ext == \"csv\"):\n",
    "        urls = extractURLs_csv(sourceFile, searchTerms, key, firstIndex, lastIndex)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    \n",
    "    # scrape and save\n",
    "    status = scrapeFromURLs(urls, combine, wait)\n",
    "    \n",
    "    # mark source file\n",
    "    if statusCol is not None:\n",
    "        if (ext == \"xlsx\"):\n",
    "            source = pd.read_excel(sourceFile)\n",
    "        elif (ext == \"csv\"):\n",
    "            source = pd.read_csv(sourceFile)\n",
    "        else:\n",
    "            raise ValueError\n",
    "        # make status list and put into source file df\n",
    "        status_final = [\"Scraped\" if s is 1 else \"Failed\" for s in status]\n",
    "        source.loc[firstIndex:lastIndex,[statusCol]] = status_final\n",
    "        if overWrite:\n",
    "            if (ext == \"xlsx\"):\n",
    "                source.to_excel(sourceFile, index=False)\n",
    "            elif (ext == \"csv\"):\n",
    "                source.to_csv(sourceFile, index=False)\n",
    "            else:\n",
    "                raise ValueError\n",
    "        else:\n",
    "            if (ext == \"xlsx\"):\n",
    "                source.to_excel(sourceFile.split('.')[0]+'_.'+ext, index=False)\n",
    "            elif (ext == \"csv\"):\n",
    "                source.to_csv(sourceFile.split('.')[0]+'_.'+ext, index=False)\n",
    "            else:\n",
    "                raise ValueError\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting 394 reviews\n",
      "scrolling...\n",
      "finished scrolling, found 393 reviews\n",
      "preparing to scrape location with key 1000804781\n",
      "scraped location with key 1000804781 with 393 reviews\n",
      "sum of all rows: 393\n",
      "total rows: 393\n"
     ]
    }
   ],
   "source": [
    "simpleScraper(sourceFile, searchTerms, key, indices=indices, wait=[1,2], combine=False, filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Name':['Tom', 'nick', 'krish', 'jack'], 'Age':[20, 21, 19, 18]} \n",
    "df = pd.DataFrame(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.google.com/search?q=Pizza Hut+10021004 Chestnut St+EMMAUS+PA\"\n",
    "driver = webdriver.Chrome('./chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)\n",
    "addr = driver.find_elements_by_xpath(\"//span[@class='LrzXr']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [0,2]\n",
    "age_final = [23, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\scrapes\\\\'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath + \"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "workfile = pd.read_excel(\"workfile.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company ID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Industry ID</th>\n",
       "      <th>Industry Name</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Address 1</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Listing Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Parent_ID</th>\n",
       "      <th>Parent Name</th>\n",
       "      <th>Parent City</th>\n",
       "      <th>google.com/search?q=Pizza%20Hut+Address 1+City+State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000805e+09</td>\n",
       "      <td>Scraped</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>142 Highway 62</td>\n",
       "      <td>ASH FLAT</td>\n",
       "      <td>AR</td>\n",
       "      <td>72513</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>8.709947e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+142 Highway 62...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.000805e+09</td>\n",
       "      <td>Scraped</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>30 W 150 N</td>\n",
       "      <td>LAGRANGE</td>\n",
       "      <td>IN</td>\n",
       "      <td>46761-9027</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2.604633e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+30 W 150 N+LAG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.000805e+09</td>\n",
       "      <td>Scraped</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1 David Dr</td>\n",
       "      <td>ESSEX JUNCTION</td>\n",
       "      <td>VT</td>\n",
       "      <td>05452-2826</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>8.028780e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+1 David Dr+ESS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.000805e+09</td>\n",
       "      <td>Scraped</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>10 Saint Francis Way</td>\n",
       "      <td>CRANBERRY TOWNSHIP</td>\n",
       "      <td>PA</td>\n",
       "      <td>16066-5130</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>7.247763e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+10 Saint Franc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.000805e+09</td>\n",
       "      <td>Scraped</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>10 W Chestnut Hill Ln</td>\n",
       "      <td>REISTERSTOWN</td>\n",
       "      <td>MD</td>\n",
       "      <td>21136-3220</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>4.108337e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+10 W Chestnut ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company ID   Status  Industry ID                 Industry Name  \\\n",
       "0  1.000805e+09  Scraped         51.0  Locations: Chain Restaurants   \n",
       "1  1.000805e+09  Scraped         51.0  Locations: Chain Restaurants   \n",
       "2  1.000805e+09  Scraped         51.0  Locations: Chain Restaurants   \n",
       "3  1.000805e+09  Scraped         51.0  Locations: Chain Restaurants   \n",
       "4  1.000805e+09  Scraped         51.0  Locations: Chain Restaurants   \n",
       "\n",
       "  Company Name              Address 1                City State         Zip  \\\n",
       "0    Pizza Hut         142 Highway 62            ASH FLAT    AR       72513   \n",
       "1    Pizza Hut             30 W 150 N            LAGRANGE    IN  46761-9027   \n",
       "2    Pizza Hut             1 David Dr      ESSEX JUNCTION    VT  05452-2826   \n",
       "3    Pizza Hut   10 Saint Francis Way  CRANBERRY TOWNSHIP    PA  16066-5130   \n",
       "4    Pizza Hut  10 W Chestnut Hill Ln        REISTERSTOWN    MD  21136-3220   \n",
       "\n",
       "  Listing Type                   Country         Phone     Parent_ID  \\\n",
       "0     Location  United States of America  8.709947e+09  1.000019e+09   \n",
       "1     Location  United States of America  2.604633e+09  1.000019e+09   \n",
       "2     Location  United States of America  8.028780e+09  1.000019e+09   \n",
       "3     Location  United States of America  7.247763e+09  1.000019e+09   \n",
       "4     Location  United States of America  4.108337e+09  1.000019e+09   \n",
       "\n",
       "        Parent Name Parent City  \\\n",
       "0  YUM! Brands Inc.  LOUISVILLE   \n",
       "1  YUM! Brands Inc.  LOUISVILLE   \n",
       "2  YUM! Brands Inc.  LOUISVILLE   \n",
       "3  YUM! Brands Inc.  LOUISVILLE   \n",
       "4  YUM! Brands Inc.  LOUISVILLE   \n",
       "\n",
       "  google.com/search?q=Pizza%20Hut+Address 1+City+State  \n",
       "0  google.com/search?q=Pizza%20Hut+142 Highway 62...    \n",
       "1  google.com/search?q=Pizza%20Hut+30 W 150 N+LAG...    \n",
       "2  google.com/search?q=Pizza%20Hut+1 David Dr+ESS...    \n",
       "3  google.com/search?q=Pizza%20Hut+10 Saint Franc...    \n",
       "4  google.com/search?q=Pizza%20Hut+10 W Chestnut ...    "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_trimmed = workfile[workfile[\"Company ID\"].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unscraped = workfile[(workfile[\"Status\"].isnull()) & (workfile[\"Company ID\"].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company ID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Industry ID</th>\n",
       "      <th>Industry Name</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Address 1</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Listing Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Parent_ID</th>\n",
       "      <th>Parent Name</th>\n",
       "      <th>Parent City</th>\n",
       "      <th>google.com/search?q=Pizza%20Hut+Address 1+City+State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>787</td>\n",
       "      <td>1.000808e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1402 E Saint Patrick St</td>\n",
       "      <td>RAPID CITY</td>\n",
       "      <td>SD</td>\n",
       "      <td>57701-3937</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>6.053424e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+1402 E Saint P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>788</td>\n",
       "      <td>1.000808e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>134 Yellow Creek Rd</td>\n",
       "      <td>EVANSTON</td>\n",
       "      <td>WY</td>\n",
       "      <td>82930-5224</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>3.077891e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+134 Yellow Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>789</td>\n",
       "      <td>1.000808e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1347 Kennedy Blvd</td>\n",
       "      <td>BAYONNE</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07002-2245</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2.014368e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+1347 Kennedy B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.000808e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1350 Big A Rd</td>\n",
       "      <td>TOCCOA</td>\n",
       "      <td>GA</td>\n",
       "      <td>30577-6013</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>7.068861e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+1350 Big A Rd+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>791</td>\n",
       "      <td>1.000808e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1350 Capitol Dr</td>\n",
       "      <td>PEWAUKEE</td>\n",
       "      <td>WI</td>\n",
       "      <td>53072-2589</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2.626956e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+1350 Capitol D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1282</td>\n",
       "      <td>1.000809e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>17539 Blanco Rd</td>\n",
       "      <td>SAN ANTONIO</td>\n",
       "      <td>TX</td>\n",
       "      <td>78232-1025</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2.104934e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+17539 Blanco R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1283</td>\n",
       "      <td>1.000809e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1754 N College Ave</td>\n",
       "      <td>FAYETTEVILLE</td>\n",
       "      <td>AR</td>\n",
       "      <td>72703-2605</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>4.795213e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+1754 N College...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1284</td>\n",
       "      <td>1.000810e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1830 Kempsville Rd</td>\n",
       "      <td>VIRGINIA BEACH</td>\n",
       "      <td>VA</td>\n",
       "      <td>23464-6860</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>7.574800e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+1830 Kempsvill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1285</td>\n",
       "      <td>1.000810e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>1835 E Vienna St</td>\n",
       "      <td>ANNA</td>\n",
       "      <td>IL</td>\n",
       "      <td>62906-2033</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>6.188335e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+1835 E Vienna ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1286</td>\n",
       "      <td>1.000810e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Locations: Chain Restaurants</td>\n",
       "      <td>Pizza Hut</td>\n",
       "      <td>18509 Woodfield Rd</td>\n",
       "      <td>GAITHERSBURG</td>\n",
       "      <td>MD</td>\n",
       "      <td>20879-4710</td>\n",
       "      <td>Location</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>3.019908e+09</td>\n",
       "      <td>1.000019e+09</td>\n",
       "      <td>YUM! Brands Inc.</td>\n",
       "      <td>LOUISVILLE</td>\n",
       "      <td>google.com/search?q=Pizza%20Hut+18509 Woodfiel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Company ID Status  Industry ID                 Industry Name  \\\n",
       "787   1.000808e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "788   1.000808e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "789   1.000808e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "790   1.000808e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "791   1.000808e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "...            ...    ...          ...                           ...   \n",
       "1282  1.000809e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "1283  1.000809e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "1284  1.000810e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "1285  1.000810e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "1286  1.000810e+09    NaN         51.0  Locations: Chain Restaurants   \n",
       "\n",
       "     Company Name                Address 1            City State         Zip  \\\n",
       "787     Pizza Hut  1402 E Saint Patrick St      RAPID CITY    SD  57701-3937   \n",
       "788     Pizza Hut      134 Yellow Creek Rd        EVANSTON    WY  82930-5224   \n",
       "789     Pizza Hut        1347 Kennedy Blvd         BAYONNE    NJ  07002-2245   \n",
       "790     Pizza Hut            1350 Big A Rd          TOCCOA    GA  30577-6013   \n",
       "791     Pizza Hut          1350 Capitol Dr        PEWAUKEE    WI  53072-2589   \n",
       "...           ...                      ...             ...   ...         ...   \n",
       "1282    Pizza Hut          17539 Blanco Rd     SAN ANTONIO    TX  78232-1025   \n",
       "1283    Pizza Hut       1754 N College Ave    FAYETTEVILLE    AR  72703-2605   \n",
       "1284    Pizza Hut       1830 Kempsville Rd  VIRGINIA BEACH    VA  23464-6860   \n",
       "1285    Pizza Hut         1835 E Vienna St            ANNA    IL  62906-2033   \n",
       "1286    Pizza Hut       18509 Woodfield Rd    GAITHERSBURG    MD  20879-4710   \n",
       "\n",
       "     Listing Type                   Country         Phone     Parent_ID  \\\n",
       "787      Location  United States of America  6.053424e+09  1.000019e+09   \n",
       "788      Location  United States of America  3.077891e+09  1.000019e+09   \n",
       "789      Location  United States of America  2.014368e+09  1.000019e+09   \n",
       "790      Location  United States of America  7.068861e+09  1.000019e+09   \n",
       "791      Location  United States of America  2.626956e+09  1.000019e+09   \n",
       "...           ...                       ...           ...           ...   \n",
       "1282     Location  United States of America  2.104934e+09  1.000019e+09   \n",
       "1283     Location  United States of America  4.795213e+09  1.000019e+09   \n",
       "1284     Location  United States of America  7.574800e+09  1.000019e+09   \n",
       "1285     Location  United States of America  6.188335e+09  1.000019e+09   \n",
       "1286     Location  United States of America  3.019908e+09  1.000019e+09   \n",
       "\n",
       "           Parent Name Parent City  \\\n",
       "787   YUM! Brands Inc.  LOUISVILLE   \n",
       "788   YUM! Brands Inc.  LOUISVILLE   \n",
       "789   YUM! Brands Inc.  LOUISVILLE   \n",
       "790   YUM! Brands Inc.  LOUISVILLE   \n",
       "791   YUM! Brands Inc.  LOUISVILLE   \n",
       "...                ...         ...   \n",
       "1282  YUM! Brands Inc.  LOUISVILLE   \n",
       "1283  YUM! Brands Inc.  LOUISVILLE   \n",
       "1284  YUM! Brands Inc.  LOUISVILLE   \n",
       "1285  YUM! Brands Inc.  LOUISVILLE   \n",
       "1286  YUM! Brands Inc.  LOUISVILLE   \n",
       "\n",
       "     google.com/search?q=Pizza%20Hut+Address 1+City+State  \n",
       "787   google.com/search?q=Pizza%20Hut+1402 E Saint P...    \n",
       "788   google.com/search?q=Pizza%20Hut+134 Yellow Cre...    \n",
       "789   google.com/search?q=Pizza%20Hut+1347 Kennedy B...    \n",
       "790   google.com/search?q=Pizza%20Hut+1350 Big A Rd+...    \n",
       "791   google.com/search?q=Pizza%20Hut+1350 Capitol D...    \n",
       "...                                                 ...    \n",
       "1282  google.com/search?q=Pizza%20Hut+17539 Blanco R...    \n",
       "1283  google.com/search?q=Pizza%20Hut+1754 N College...    \n",
       "1284  google.com/search?q=Pizza%20Hut+1830 Kempsvill...    \n",
       "1285  google.com/search?q=Pizza%20Hut+1835 E Vienna ...    \n",
       "1286  google.com/search?q=Pizza%20Hut+18509 Woodfiel...    \n",
       "\n",
       "[500 rows x 16 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscraped.iloc[0:500,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = np.array_split(work_trimmed, len(work_trimmed)/500)\n",
    "for df in dfs:\n",
    "    first_index = str(df.first_valid_index())\n",
    "    last_index = str(df.last_valid_index())\n",
    "    filename = \"workfile_\" + first_index + \"_\" + last_index + \".xlsx\"\n",
    "    df.to_excel(filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1291'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(dfs[0].last_valid_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9/29/20 3:21 scrape\n",
    "# 256-306 (50 locations)\n",
    "searchTerms = [\"Company Name\", \"Address 1\", \"City\", \"State\"]\n",
    "key = \"Company ID\"\n",
    "sourceFile = \"workfile_530_1059.xlsx\"\n",
    "indices = list(range(256,307))\n",
    "filePath = \"C:\\\\Users\\\\Spencer\\\\Desktop\\\\scrape\\\\py_files\\\\scrapes\"\n",
    "# simpleScraper(sourceFile=sourceFile, searchTerms=searchTerms, key=key, indices=indices, wait=[1,2], combine=False, statusCol=\"Status\", filePath=filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(256,530))[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
