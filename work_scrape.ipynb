{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrollDown(driver, reviewTotal, wait):\n",
    "    x = len(driver.find_elements_by_xpath(\"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\"))\n",
    "    lastx = x - 1\n",
    "    i = 1\n",
    "    repCount = 0\n",
    "    while ((x < reviewTotal) and (repCount < 2)):\n",
    "        pauseScroll(wait)\n",
    "        elements = driver.find_elements_by_xpath(\"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\")\n",
    "        current_last = elements[-1]\n",
    "        current_last.location_once_scrolled_into_view\n",
    "        lastx = x\n",
    "        x = len(driver.find_elements_by_xpath(\"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\"))\n",
    "        if (lastx == x):\n",
    "            repCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReviewTotal(driver):\n",
    "    raw = driver.find_element_by_xpath(\"//span[@class='hqzQac']\").text\n",
    "    count = int(raw.split(\" \")[0])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numbers\n",
    "import time\n",
    "def pauseScroll(wait):\n",
    "    waitTime = 0\n",
    "    # if argument is a list\n",
    "    if (isinstance(wait, list)):\n",
    "        # check if its length is valid\n",
    "        if (len(wait) > 2) or (len(wait) < 1):\n",
    "            raise ValueError\n",
    "        # if length is valid get random number between vals\n",
    "        low = wait[0]\n",
    "        high = wait[1]\n",
    "        # check for improper types, fix if possible\n",
    "        if not isinstance(low, numbers.Number):\n",
    "            if low.isnumeric():\n",
    "                low = float(low)\n",
    "            else:\n",
    "                raise ValueError\n",
    "        if not isinstance(high, numbers.Number):\n",
    "            if high.isnumeric():\n",
    "                high = float(high)\n",
    "            else:\n",
    "                raise ValueError\n",
    "        waitTime = randTime(low, high)\n",
    "    # if argument is a number\n",
    "    elif (isinstance(wait, numbers.Number)):\n",
    "        # get the number\n",
    "        waitTime = wait\n",
    "    # if argument is a string\n",
    "    elif (isinstance(wait, str)):\n",
    "        # if argument can be parsed as a number\n",
    "        if (wait.isnumeric()):\n",
    "            # get time as a number\n",
    "            waitTime = float(wait)\n",
    "        else:\n",
    "            raise ValueError\n",
    "    time.sleep(waitTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "def randTime(low, high):\n",
    "    val = random()\n",
    "    time = low + (val  * (high - low))\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "# note that this assumes scrolling has already occurred\n",
    "def scrapeFromList(driver, id=None, name=True, stars=True, text=True, timeSince=True):\n",
    "    elements = driver.find_elements_by_xpath(\"//div[@class='gws-localreviews__general-reviews-block']//div[@class='WMbnJf gws-localreviews__google-review']\")\n",
    "    columnsBin = [name, stars, text, timeSince]\n",
    "    columnsNames = [\"name\", \"stars\", \"text\", \"timeSince\"]\n",
    "    columnsPresent = [x for i, x in enumerate(columnsNames) if columnsBin[i]] # gets included columns\n",
    "    \n",
    "    # text body\n",
    "    textList = []\n",
    "    if (text):\n",
    "        textPath = \".//div[@style='vertical-align:top']//div[@class='Jtu6Td']//span[@jscontroller='P7L8k']\"\n",
    "        textPathFullExtension = \"//span[@class='review-full-text']\"\n",
    "        textList = [0]*len(elements)\n",
    "        i = 0\n",
    "        for e in elements:\n",
    "            try:\n",
    "                textPartial = e.find_element_by_xpath(textPath+textPathFullExtension)\n",
    "                e.find_element_by_xpath(textPath+\"//span[@role='button']\").click()\n",
    "                textList[i] = e.find_element_by_xpath(textPath).text\n",
    "            except NoSuchElementException:\n",
    "                textList[i] = e.find_element_by_xpath(textPath).text\n",
    "            i += 1\n",
    "        \n",
    "    # name\n",
    "    nameList = []\n",
    "    if (name):\n",
    "        namePath = \".//div[@class='TSUbDb']\"\n",
    "        nameList = [e.find_element_by_xpath(namePath).text for e in elements]\n",
    "    \n",
    "    # stars\n",
    "    starsList = []\n",
    "    if (stars):\n",
    "        starsPath = \".//div[@style='vertical-align:top']//div[@class='PuaHbe']//g-review-stars[@style='padding-right:7px']//span[@class='Fam1ne EBe2gf']\"\n",
    "        i = 0\n",
    "        starsList = [0]*len(elements)\n",
    "        for e in elements:\n",
    "            raw = e.find_element_by_xpath(starsPath).get_attribute(\"aria-label\")\n",
    "            starCount = raw.split(\" \")[1] # the number of stars\n",
    "            starsList[i] = float(starCount)\n",
    "            i += 1\n",
    "    \n",
    "    # timeSince\n",
    "    timeSinceList = []\n",
    "    if (timeSince):\n",
    "        timeSincePath = \".//div[@style='vertical-align:top']//div[@class='PuaHbe']\"\n",
    "        timeSinceList = [e.find_element_by_xpath(timeSincePath).text for e in elements]\n",
    "    \n",
    "    # put df together\n",
    "    columnsBin = [name, stars, text, timeSince]\n",
    "    columnsNames = [\"name\", \"stars\", \"text\", \"timeSince\"]\n",
    "    columnsPresent = [x for i, x in enumerate(columnsNames) if columnsBin[i]] # gets included columns\n",
    "    columns = [nameList, starsList, textList, timeSinceList]\n",
    "    columns = [c for c in columns if len(c) > 0]\n",
    "    data = {c:columns[i] for i,c in enumerate(columnsPresent)}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "def scrapeFromURLs(urls, combine=True, wait=[2,3]):\n",
    "    # check that urls are dicts\n",
    "    if not (isinstance(urls, dict)):\n",
    "        raise ValueError\n",
    "        \n",
    "    # start selenium stuff\n",
    "    driver = webdriver.Chrome('./chromedriver')\n",
    "    \n",
    "    dfs = [0]*len(urls)\n",
    "    \n",
    "    # for each id\n",
    "    i = 0\n",
    "    for id in urls:\n",
    "        url = urls.get(id)\n",
    "        driver.get(url) # go to url\n",
    "        driver.find_element_by_class_name(\"hqzQac\").click()\n",
    "        WebDriverWait(driver, 10).until(ec.presence_of_element_located((By.XPATH, \"//div[@class='AU64fe']\")))\n",
    "        \n",
    "        # scroll to bottom\n",
    "        scrollDown(driver, getReviewTotal(driver), wait)\n",
    "        \n",
    "        # scrape from loaded list\n",
    "        df = scrapeFromList(driver, id)\n",
    "        \n",
    "        dfs[i] = df\n",
    "        i += 1\n",
    "        \n",
    "    # combine dfs if necessary\n",
    "    if (combine):\n",
    "        df = dfs[0]\n",
    "        # append all other dfs to the first one, then save to csv\n",
    "        for i in dfs[1:]:\n",
    "            df = df.append(i, ignore_index=True)\n",
    "        df.to_csv(\"combined_scrape_\"+str(datetime.datetime.now()).replace(' ','_').replace(':','_').replace('.','_')+\".csv\",index=False)\n",
    "    else:\n",
    "        for i in dfs:\n",
    "            i.to_csv(\"scraped_\"+str(datetime.datetime.now()).replace(' ','_').replace(':','_').replace('.','_')+\".csv\",index=False)\n",
    "        \n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# make scrapeFromURLs take in a filename convention and have csvs save as it\n",
    "# add check for correct address\n",
    "# check that reviews button is there, i.e. check whether there is actually a location found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-53274d23d3e7>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-53274d23d3e7>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    search = df.loc[]\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def extractURLS(csv, searchTerms, keys, firstIndex, lastIndex):\n",
    "    baseString = \"google.com/search?q=\"\n",
    "    \n",
    "    # read in csv (maybe add value checks later)\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    #search = df.loc[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "testURLs = {1:\"https://www.google.com/search?q=pizza+hut+142+highway+62+ash+flat+ar\", 2:\"https://www.google.com/search?q=pizza+hut+620+lincoln+way+ames+ia\"}\n",
    "\n",
    "testdf = scrapeFromURLs(testURLs)\n",
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
